{
	"metadata": {
		"colab": {
			"provenance": []
		},
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "import pyspark\n\nfrom pyspark import SparkContext\nsc = SparkContext.getOrCreate()\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "LwAe9itlFkGw"
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nSession ID: 52118ca7-4d12-40b2-ad15-d303279e0911\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session 52118ca7-4d12-40b2-ad15-d303279e0911 to get into ready status...\nSession 52118ca7-4d12-40b2-ad15-d303279e0911 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import functions as F",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "l20rmqkOA2Mq"
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 1: Import data from google drive</h2>",
			"metadata": {
				"id": "mZ4e-YxiF1y1"
			}
		},
		{
			"cell_type": "code",
			"source": "user_df = spark.read.parquet(\"s3://music-preference-bucket/user_data/\")\ntop_artists_df = spark.read.parquet(\"s3://music-preference-bucket/top_artists/\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "5ZslP0X7HZ3K"
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 2: Clean the data</h2>",
			"metadata": {
				"id": "9l6uuxGYNt-F"
			}
		},
		{
			"cell_type": "code",
			"source": "#drop users with null country for both df\ndrop_ids_df = user_df.filter(user_df['country'].isNull()).select('user_id')\ntop_artists_df = top_artists_df.join(drop_ids_df, how='left_anti', on='user_id').drop('mbid')\nuser_df = user_df.dropna(subset=['country'])",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Clean up playcount and cast into integers\ntop_artists_df = top_artists_df.withColumn(\n    \"playcount_cast\",\n    F.expr(\"try_cast(playcount as int)\")\n)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "31PqF1uKWfMb",
				"outputId": "f4438e99-9e88-4089-b106-acfe6378f192"
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "insert the average of playcount before and after for null playcounts",
			"metadata": {
				"id": "SELYFSFbBLc1"
			}
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.window import Window\n#insert the average of playcount before and after for null playcounts\nw = Window.partitionBy(\"user_id\").orderBy(\"rank\") #groups users\ntop_artists_df = top_artists_df.withColumn(\n    \"prev_value\",\n    F.last(\"playcount_cast\", ignorenulls=True).over(w.rowsBetween(-1, -1)) #apply last on user\n).withColumn(\n    \"next_value\",\n    F.first(\"playcount_cast\", ignorenulls=True).over(w.rowsBetween(1, 1))\n)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "Bs4-WkmzWfWR"
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "top_artists_df = top_artists_df.withColumn(\n    \"cleaned_playcount\",\n    F.when(\n        F.col(\"playcount_cast\").isNull() & F.col(\"prev_value\").isNull(),\n        F.col(\"next_value\")\n    ).when(\n        F.col(\"playcount_cast\").isNull() & F.col(\"next_value\").isNull(),\n        F.col(\"prev_value\")\n    ).when(\n        F.col(\"playcount_cast\").isNull(),\n        (F.col(\"prev_value\") + F.col(\"next_value\")) / 2\n    ).otherwise(top_artists_df.playcount_cast.cast(\"int\"))\n)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "Pj92hayvbJW7"
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "top_artists_df = top_artists_df.drop(\"playcount\", \"playcount_cast\", \"prev_value\", \"next_value\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "_V9Z8NH1NVQ-"
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#store cleaned data into s3\nuser_df.write.parquet(\"s3://music-preference-bucket/cleaned_user_data/\", mode=\"overwrite\")\ntop_artists_df.write.parquet(\"s3://music-preference-bucket/cleaned_top_artists/\", mode=\"overwrite\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "NameError: name 'user_df' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 3: create sequence to be fed into word2vec model</h2>",
			"metadata": {
				"id": "wHm2UQDYUuTJ"
			}
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import functions as F\n#create column to store weight of each artist\nweighted_df = top_artists_df.withColumn(\"weight\", F.round(1 + F.log10(F.col('cleaned_playcount'))).cast(\"int\"))",
			"metadata": {
				"trusted": true,
				"tags": [],
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "YeHXDcBzHgMV",
				"outputId": "bc0776e0-80fc-4d0e-a8cb-f3a0acbe847d"
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#create column that repeats the artist's name according to weight\nuser_sequence_df = weighted_df.withColumn(\"artist_weighted\", F.array_repeat(\"artist_name\", F.col(\"weight\")))",
			"metadata": {
				"trusted": true,
				"tags": [],
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "v3_JUyMhIlvz",
				"outputId": "70234d78-ebec-4ec3-a530-da6c6cb70db0"
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#explode the artist_weighted array into multiple rows\nexpanded_df = (\n    user_sequence_df\n        .withColumn(\"artist\", F.explode(\"artist_weighted\"))\n)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"colab": {
					"base_uri": "https://localhost:8080/"
				},
				"id": "NM6Xfyp-PSd1",
				"outputId": "224cda20-02a4-4d43-b2cd-fc4c45a59d2f"
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_sequences = expanded_df.select(\"user_id\", \"rank\", \"artist\").orderBy(\"user_id\", \"rank\").groupBy(\"user_id\").agg(F.collect_list(\"artist\").alias(\"user_sequence\"))",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "LLsfMu_cQ7Pt"
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_sequences.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+--------------------+\n|user_id|       user_sequence|\n+-------+--------------------+\n|     12|[O√∂phoi, O√∂phoi...|\n|     18|[The Dillinger Es...|\n|     38|[Bondage Fairies,...|\n|     67|[A Day to Remembe...|\n|     70|[U2, U2, U2, U2, ...|\n+-------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 4: use word2vec to form embedding</h2>",
			"metadata": {
				"id": "3GnVSUPS7Ii_"
			}
		},
		{
			"cell_type": "code",
			"source": "from pyspark.ml.feature import Word2Vec\ndims = 128\n\nw2v_model = Word2Vec(\n    vectorSize = dims,\n    windowSize = 5,\n    minCount = 2,\n    numPartitions = 4,\n    inputCol = \"user_sequence\",\n    outputCol = \"user_embedding\"\n)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "y2lXVuM87PUi"
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "w2v_model = w2v_model.fit(user_sequences)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"id": "ZIfZUSOfF0oZ"
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 5: Store model into s3</h2>",
			"metadata": {
				"id": "VQ5pjTnE_8bb"
			}
		},
		{
			"cell_type": "code",
			"source": "import boto3\nw2v_model.getVectors().write.parquet(\"s3://music-preference-bucket/artist_embeddings/\", mode=\"overwrite\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 35,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "w2v_model.getVectors().columns",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 41,
			"outputs": [
				{
					"name": "stdout",
					"text": "['word', 'vector']\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "artist_embeddings_df = w2v_model.getVectors()",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 6: create embedding for each user</h2>",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "artist_embeddings_df = spark.read.parquet(\"s3://music-preference-bucket/artist_embeddings/\")\nuser_df = spark.read.parquet(\"s3://music-preference-bucket/cleaned_user_data/\")\ntop_artists_df = spark.read.parquet(\"s3://music-preference-bucket/cleaned_top_artists/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.conf.set(\"spark.sql.shuffle.partitions\", \"1000\")\nspark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#make artist embedding vector into array\nartist_embeddings_df = artist_embeddings_df.select(\n    F.col(\"word\").alias(\"artist_name\"),\n    vector_to_array(\"vector\").alias(\"emb\")\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#add artist embedding and weight to top_artists_df \nuser_artist = (\n    top_artists_df\n    .join(artist_embeddings_df, on=\"artist_name\", how=\"inner\")\n    .withColumn(\"weight\", F.log10(F.col(\"cleaned_playcount\") + 1))\n    .select(\"user_id\", \"rank\", \"weight\", \"emb\")\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#repartition to avoide spill\nuser_artist = (\n    user_artist\n    .repartition(1000, \"user_id\")\n)\n\nuser_scaled_embeddings = (\n    user_artist\n    .groupBy(\"user_id\")\n    .agg(\n        F.sum(\"weight\").alias(\"weight_sum\"),\n        F.aggregate(\n            F.collect_list(\n                F.transform(\"emb\", lambda x: x * F.col(\"weight\"))\n            ),\n            F.array_repeat(F.lit(0.0), 128),\n            lambda acc, x: F.transform(acc, lambda v, i: v + x[i])\n        ).alias(\"sum_vec\")\n    )\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#produce the weighted mean\nuser_embeddings_df = user_scaled_embeddings.select(\n    \"user_id\",\n    F.transform(\n        \"sum_vec\",\n        lambda x: x / F.col(\"weight_sum\")\n    ).alias(\"user_embedding\")\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_embeddings_df = user_embeddings_df.join(user_df, \"user_id\", \"inner\")\n\n(\n    user_embeddings_df\n    .repartition(500, \"user_id\")\n    .write\n    .mode(\"overwrite\")\n    .parquet(\"s3://music-preference-bucket/user_embeddings/\")\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_embeddings_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+--------------------+------------------+---------------+\n|user_id|      user_embedding|           country|total_scrobbles|\n+-------+--------------------+------------------+---------------+\n|    148|[0.03456595002237...|     United States|            562|\n|    496|[-0.0449543348938...|Russian Federation|         143124|\n|    833|[-0.1019500409192...|     United States|         104176|\n|   1088|[-0.1010368947044...|     United States|          45845|\n|   1342|[-0.0139159571897...|            Sweden|           9363|\n+-------+--------------------+------------------+---------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_embeddings_df.first()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 49,
			"outputs": [
				{
					"name": "stdout",
					"text": "Row(user_id=12, user_embedding=[-0.05067372235991417, 0.1007816418829873, 0.08870364404594912, -0.006708111050205171, -0.03327242270202116, -0.019926956026419685, 0.009964543948663415, -0.006480001971371798, -0.03787271198840715, 0.10043763767232697, -0.008331445356425514, -0.09697475059963026, -0.04078526977245786, 0.004657762098244807, 0.02793102165691815, -0.05218308891780549, 0.014877170603089783, -0.07451262988606067, -0.01737810529402924, 0.0365440879316109, -0.0782646253015479, 0.042127161199509634, 0.06919779272842522, 0.037412218520038974, -0.016570137145054908, 0.04536218840300717, -0.0782227337125071, -0.0033580802221653445, -0.05680549727642077, -0.02785061593556387, 0.008981319812882587, 0.04215886901176896, -0.08552669300155082, -0.04877689186301139, -0.04878971818160236, -0.060486754719238055, -0.007742160710013353, -0.08728634633140232, 0.06062000669702991, 0.05673156396420344, -0.12089280510471297, -0.030363310646490473, 0.10181451185427406, 0.03816320530519724, -0.023433032225766433, -0.06400105622369484, 0.003643313769484703, 0.027880093366202816, 0.024163518578606335, -0.07012431897024828, 0.022966198259194357, -0.03774700944109977, 0.015473949254863922, -0.05654964477824245, -0.025527247085231426, 0.043824577910988496, -0.08802345184120884, -0.023081612362423187, -0.05551096111751607, 0.06157398286099779, -0.022324820456340905, 0.0054366967985292, 0.07778041435242639, -0.07845851175086035, -0.09615759715304864, 0.01202505539419359, 0.03667225923395307, -0.07756537120543912, 0.05277925460189049, 0.029554258106666138, 0.016662258511978383, 0.038518790675367315, 0.03687836026136752, 0.0012725548044610212, 0.047894183168611305, -0.05151848318677134, -0.010260347609332181, 0.03725127308346648, -0.00789430392267887, 0.05416134263257201, -0.03691462886351037, 0.029858137419058475, 0.009930614318240877, -0.045170840572054026, -0.03847214414396183, 0.005501825850941573, 0.026839040993050373, 0.07793214681831655, -0.05970399111610048, -0.008187895351291287, 0.023927920629580653, -0.030821073855097844, -0.0329541461002153, 0.023735624736104216, 0.002800012787424787, 0.006105915188763367, -0.03234970243489823, 0.13735452106800164, -0.07092783425903135, -0.10934192558328605, 0.04535264674502724, 0.07937890619616919, -0.008972836622537022, -0.02390091954007061, 0.05781363390364574, 0.046165823412043394, 0.13361914379744894, -0.00873129070274875, -0.06470012125999128, 0.023181215212257304, 0.08162912318192046, 0.03368404137227163, 0.0049945838211700394, -0.028970560061119973, 0.1455215653629551, -0.006546366270291888, 0.1056643567867546, 0.028976410747881393, -0.012570434343490791, -0.08799174079406248, 0.013039767097976815, 0.019777291938201005, 0.0036903507790733052, 0.04809054008426782, 0.07620841564100832, -0.03592994600919098, 0.10295772202336675, 0.08686302175488923], country='Italy', total_scrobbles=93273)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 7: clean up the dataset</h2>",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "user_embeddings_df = spark.read.parquet(\"s3://music-preference-bucket/user_embeddings/\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#seperaate the dimensions into columns\nn_dim = len(user_embeddings_df.first().user_embedding)\n\nfor i in range(n_dim):\n    user_embeddings_df = user_embeddings_df.withColumn(\n        f\"dim_{i}\",\n        F.col(\"user_embedding\")[i]\n    )\n    \nuser_embeddings_df = user_embeddings_df.drop(\"user_embedding\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#drop users with null scrobbles then log scale total scrobbles\nuser_embeddings_df = user_embeddings_df.filter(~F.col(\"total_scrobbles\").isNull())\nuser_embeddings_df = user_embeddings_df.withColumn(\n    \"log_scaled_scrobbles\",\n    F.log(\"total_scrobbles\")\n).drop(\"total_scrobbles\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#filter out users with no country label\nuser_embeddings_df = user_embeddings_df.filter(F.col(\"country\").isNotNull() & \n                                               (~F.lower(F.trim(F.col(\"country\"))).isin(\"none\", \"null\", \"\")))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#filter out countries with less than 50 users\nrare_countries = user_embeddings_df.select(\"country\").groupBy(\"country\").count().filter(F.col(\"count\") <= 50).select(\"country\")\nuser_embeddings_df = user_embeddings_df.join(rare_countries, on='country', how='left_anti')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "user_embeddings_df.select(\"country\").groupBy(\"country\").count().orderBy(F.col(\"count\")).show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+-----+\n|             country|count|\n+--------------------+-----+\n|               Niger|   53|\n|           Nicaragua|   53|\n|            Mongolia|   54|\n|Syrian Arab Republic|   54|\n|Virgin Islands, B...|   56|\n+--------------------+-----+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "<h2>Step 9: divide train validation test datasets</h2>",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "user_embeddings_df = user_embeddings_df.withColumn(\n    \"bucket\",\n    F.expr(\"pmod(hash(user_id), 100)\")\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "train_df = user_embeddings_df.filter(F.col(\"bucket\") < 80).drop(\"bucket\")\nval_df   = user_embeddings_df.filter((F.col(\"bucket\") >= 80) & (F.col(\"bucket\") < 90)).drop(\"bucket\")\ntest_df  = user_embeddings_df.filter(F.col(\"bucket\") >= 90).drop(\"bucket\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#check that all countries are in each dataset\nprint(\"total countries: \", user_embeddings_df.select(\"country\").distinct().count())\nprint(\"training dataset: \", train_df.select(\"country\").distinct().count())\nprint(\"test dataset: \", test_df.select(\"country\").distinct().count())\nprint(\"validation dataset: \", val_df.select(\"country\").distinct().count())",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "total countries:  119\ntraining dataset:  119\ntest dataset:  119\nvalidation dataset:  119\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#check number of rows in each dataset\nprint(\"total countries: \", user_embeddings_df.count())\nprint(\"training dataset: \", train_df.count())\nprint(\"test dataset: \", test_df.count())\nprint(\"validation dataset: \", val_df.count())",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 29,
			"outputs": [
				{
					"name": "stdout",
					"text": "total countries:  319554\ntraining dataset:  255437\ntest dataset:  31994\nvalidation dataset:  32123\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "(\n    train_df\n    .write\n    .mode(\"overwrite\")\n    .parquet(\"s3://music-preference-bucket/train/\")\n)\n\n\n(\n    val_df\n    .write\n    .mode(\"overwrite\")\n    .parquet(\"s3://music-preference-bucket/validation/\")\n)\n\n(\n    test_df\n    .write\n    .mode(\"overwrite\")\n    .parquet(\"s3://music-preference-bucket/test/\")\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}